{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf0d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of test CAPTCHAs: 228\n",
      "# correctly recognized: 216\n",
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import imutils\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from lab_2_helpers import *\n",
    "\n",
    "CAPTCHA_IMAGE_FOLDER = \"./captcha-images\"\n",
    "TVT_SPLIT_SEED = 31528476\n",
    "CHAR_IMAGE_FOLDER = f\"./char-images-{TVT_SPLIT_SEED}\"\n",
    "MODEL_WEIGHTS_PATH = \"./captcha-model.pt\"\n",
    "LABELS_PATH = \"./labels.pkl\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "captcha_image_paths = list(paths.list_images(CAPTCHA_IMAGE_FOLDER))\n",
    "\n",
    "def extract_captcha_text(image_path):\n",
    "    return os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "captcha_texts = [extract_captcha_text(p) for p in captcha_image_paths]\n",
    "\n",
    "def load_transform_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.copyMakeBorder(image, 8, 8, 8, 8, cv2.BORDER_CONSTANT, value=255)\n",
    "    return image\n",
    "\n",
    "captcha_images = [load_transform_image(p) for p in captcha_image_paths]\n",
    "\n",
    "captcha_images_tv, captcha_images_test, captcha_texts_tv, captcha_texts_test = train_test_split(\n",
    "    captcha_images, captcha_texts, test_size=0.2, random_state=TVT_SPLIT_SEED\n",
    ")\n",
    "\n",
    "def extract_chars(image):\n",
    "    image = image.astype(\"uint8\")\n",
    "\n",
    "    thresh = cv2.threshold(\n",
    "        image, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )[1]\n",
    "\n",
    "    contours = cv2.findContours(\n",
    "        thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )[0]\n",
    "\n",
    "    regions = []\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if w / h > 1.25:\n",
    "            half = w // 2\n",
    "            regions.append((x, y, half, h))\n",
    "            regions.append((x + half, y, half, h))\n",
    "        else:\n",
    "            regions.append((x, y, w, h))\n",
    "\n",
    "    if len(regions) < 4:\n",
    "        return None\n",
    "\n",
    "    regions = sorted(regions, key=lambda r: r[2] * r[3], reverse=True)[:4]\n",
    "    regions = sorted(regions, key=lambda r: r[0])\n",
    "\n",
    "    chars = []\n",
    "    H, W = image.shape\n",
    "    for x, y, w, h in regions:\n",
    "        x1, y1 = max(x - 2, 0), max(y - 2, 0)\n",
    "        x2, y2 = min(x + w + 2, W), min(y + h + 2, H)\n",
    "        char = image[y1:y2, x1:x2]\n",
    "        if char.size == 0:\n",
    "            return None\n",
    "        chars.append(char)\n",
    "\n",
    "    return chars\n",
    "\n",
    "char_counts = {}\n",
    "\n",
    "def save_chars(char_images, captcha_text):\n",
    "    for img, ch in zip(char_images, captcha_text):\n",
    "        folder = os.path.join(CHAR_IMAGE_FOLDER, ch)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        count = char_counts.get(ch, 1)\n",
    "        cv2.imwrite(os.path.join(folder, f\"{count}.png\"), img)\n",
    "        char_counts[ch] = count + 1\n",
    "\n",
    "if not os.path.exists(CHAR_IMAGE_FOLDER):\n",
    "    for img, txt in zip(captcha_images_tv, captcha_texts_tv):\n",
    "        chars = extract_chars(img)\n",
    "        if chars:\n",
    "            save_chars(chars, txt)\n",
    "\n",
    "def make_feature(image):\n",
    "    image = resize_to_fit(image, 20, 20)\n",
    "    image = image.astype(\"float32\") / 255.0\n",
    "    return image[np.newaxis, :, :]\n",
    "\n",
    "def make_feature_label(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return make_feature(img), path.split(os.path.sep)[-2]\n",
    "\n",
    "features, labels = zip(*[\n",
    "    make_feature_label(p) for p in paths.list_images(CHAR_IMAGE_FOLDER)\n",
    "])\n",
    "\n",
    "features = np.array(features)\n",
    "lb = LabelBinarizer()\n",
    "labels_oh = lb.fit_transform(labels)\n",
    "\n",
    "with open(LABELS_PATH, \"wb\") as f:\n",
    "    pickle.dump(lb, f)\n",
    "\n",
    "y = np.argmax(labels_oh, axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, y, test_size=0.25, random_state=955996\n",
    ")\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_loader = DataLoader(CharDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(CharDataset(X_val, y_val), batch_size=BATCH_SIZE)\n",
    "\n",
    "class CaptchaCNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 20, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(20, 50, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(50 * 5 * 5, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(500, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = CaptchaCNN(len(lb.classes_)).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(Xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_WEIGHTS_PATH)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_WEIGHTS_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "with open(LABELS_PATH, \"rb\") as f:\n",
    "    lb = pickle.load(f)\n",
    "\n",
    "preds_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img in captcha_images_test:\n",
    "        chars = extract_chars(img)\n",
    "        if chars is None:\n",
    "            preds_test.append(\"-\")\n",
    "            continue\n",
    "\n",
    "        out = []\n",
    "        for c in chars:\n",
    "            feat = make_feature(c)\n",
    "            feat = torch.tensor(feat).unsqueeze(0).to(device)\n",
    "            idx = model(feat).argmax(dim=1).item()\n",
    "            out.append(lb.classes_[idx])\n",
    "        preds_test.append(\"\".join(out))\n",
    "\n",
    "n_correct = sum(p == a for p, a in zip(preds_test, captcha_texts_test))\n",
    "\n",
    "print(\"# of test CAPTCHAs:\", len(captcha_texts_test))\n",
    "print(\"# correctly recognized:\", n_correct)\n",
    "print(\"Accuracy:\", n_correct / len(captcha_texts_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "467",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
